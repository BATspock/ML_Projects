{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/BATspock/ML_Projects/blob/main/whisper/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Whisper for performance on audio files and coonverted audio files from videos\n",
    "\n",
    "- Whisper installation with pytorch working in this notbook\n",
    "-  Compare performance of different whisper models and create report\n",
    "- Detailed whipser installation at https://github.com/openai/whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2eYWxJzVWIk"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with video files from YouTube using YouTube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import youtube_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create audio (mp3) files from YouTube videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_mp3(url):\n",
    "    \"\"\"\n",
    "    Save a YouTube video URL to mp3.\n",
    "\n",
    "    Args:\n",
    "        url (str): A YouTube video URL.\n",
    "\n",
    "    Returns:\n",
    "        str: The filename of the mp3 file.\n",
    "    \"\"\"\n",
    "\n",
    "    options = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with youtube_dl.YoutubeDL(options) as downloader:\n",
    "        downloader.download([\"\" + url + \"\"])\n",
    "                \n",
    "    return downloader.prepare_filename(downloader.extract_info(url, download=False)).replace(\".m4a\", \".mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert YouTube videos to mp3 and create audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This url is British PM Liz Truss giving a speech\n",
    "youtube_url = \"https://www.youtube.com/watch?v=UFNRUuBARM4\"\n",
    "# additional links for testing purposes\n",
    "# this link contains a video with a duration of 1:56 of French people speaking in English\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=iwto58Wc2bg&ab_channel=Frenchly\"\n",
    "filename = save_to_mp3(youtube_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert audio file saved to transcribe text using whisper\n",
    "\n",
    "### Trying with different size whisper models\n",
    "- tiny\t39 M\ttiny.en\ttiny\t~1 GB\t~32x\n",
    "- base\t74 M\tbase.en\tbase\t~1 GB\t~16x\n",
    "- small\t244 M\tsmall.en\tsmall\t~2 GB\t~6x\n",
    "- medium\t769 M\tmedium.en\tmedium\t~5 GB\t~2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{tiny.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"tiny.en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe text using transcribe function and check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = timeit.default_timer()\n",
    "result = model.transcribe(filename, fp16=False)\n",
    "#result['text']\n",
    "print(\"Time taken to transcribe: \", timeit.default_timer() - time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{base.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = timeit.default_timer()\n",
    "model = whisper.load_model(\"base.en\")\n",
    "result = model.transcribe(filename, fp16=False)\n",
    "#result['text']\n",
    "print(\"Time taken to transcribe using base model: \", timeit.default_timer() - timer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{small.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = timeit.default_timer()\n",
    "model = whisper.load_model(\"small.en\")\n",
    "result = model.transcribe(filename, fp16=False)\n",
    "#result['text']\n",
    "print(\"Time taken to transcribe using small model: \", timeit.default_timer() - timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{medium.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = timeit.default_timer()\n",
    "model = whisper.load_model(\"medium.en\")\n",
    "result = model.transcribe(filename, fp16=False)\n",
    "#result['text']\n",
    "print(\"Time taken to transcribe using medium model: \", timeit.default_timer() - timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation with english translations\n",
    "\n",
    "1. Performance of tiny model is much faster compared to other larger models\n",
    "2. Whisper is able to discern clearly between speaker and background noise\n",
    "3. Base model explicitly mentions \"APPLUSES\" during transcription\n",
    "4. Whisper is also able to understand the semantics as \"Norfolk turkey\" has been identified as a food dish by every model except for the base model which identifies it more as a conjugation of countries, that is : \"Norfolk, Turkey\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check performance on video where French speakers are speaking English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url_french = \"https://www.youtube.com/watch?v=iwto58Wc2bg&ab_channel=Frenchly\"\n",
    "filename_french = save_to_mp3(youtube_url_french)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{tiny.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = timeit.default_timer()\n",
    "model = whisper.load_model(\"tiny.en\")\n",
    "result = model.transcribe(filename_french, fp16=False)\n",
    "#result['text']\n",
    "print(\"Time taken to transcribe French speech using tiny model: \", timeit.default_timer() - timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{base.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = timeit.default_timer()\n",
    "model = whisper.load_model(\"base.en\")\n",
    "result = model.transcribe(filename_french, fp16=False)\n",
    "result['text']\n",
    "print(\"Time taken to transcribe French speech using base model: \", timeit.default_timer() - timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{small.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = timeit.default_timer()\n",
    "model = whisper.load_model(\"small.en\")\n",
    "result = model.transcribe(filename_french, fp16=False)\n",
    "#result['text']\n",
    "print(\"Time taken to transcribe French speech using small model: \", timeit.default_timer() - timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of $\\textbf{medium.en}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"medium.en\")\n",
    "result = model.transcribe(filename_french, fp16=False)\n",
    "result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "- The tiny model is the fastest and the least accurate\n",
    "- The accuracies in the models is very clear as the models get bigger\n",
    "- The base model is able to capture French from english parts of the audio, especially for cases such as \"to Tour-F-L. Yeah, it's F-L Tour\", for (Effiel Tower) and French words from the speaker such as \"Le Divan du Monde\"\n",
    "- $\\textbf{Need to Investigate Further}$: The medium model seem to run out of memory for French audio which it should not as it worked with English audio \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Aanlysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import for the next process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance \n",
    "import moviepy.editor as mp\n",
    "import whisper\n",
    "import timeit\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to convert all video files to audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_to_audio(video_file_path):\n",
    "    #convert video mp4 to mp3\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    clip = mp.VideoFileClip(video_file_path)\n",
    "    clip.audio.write_audiofile(video_file_path.replace(\".mp4\",\".mp3\"))\n",
    "    #move converted audio file to audio folder\n",
    "    audio_file = video_file_path.replace(\".mp4\",\".mp3\")\n",
    "    audio_file = audio_file.split('/')[-1]\n",
    "    os.replace('Data/'+audio_file,'audio/'+audio_file)\n",
    "    #transcribe the audio file\n",
    "    print(\"Time Taken to transcribe the audio file:\",timeit.default_timer()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert video files to transcribed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(audio_file_path, xml_path, model_type = 'tiny.en'):\n",
    "\n",
    "    #print(\"Converting video to audio\")\n",
    "    \n",
    "    print(\"audio file path:\",'audio/'+ audio_file_path)\n",
    "    print(\"xml file path:\",xml_path)\n",
    "    print('#'*50)\n",
    "\n",
    "    #transcribe the audio file\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    model = whisper.load_model(model_type)\n",
    "    result = model.transcribe('audio/'+ audio_file_path, fp16=False)\n",
    "\n",
    "    transcription_time = timeit.default_timer() - start_time\n",
    "    print(\"Time Taken to transcribe the audio file:\",transcription_time)\n",
    "    \n",
    "    whisper_output = result['text'].split()\n",
    "    #extract the text from the xml file\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    tree = ET.parse(xml_path)\n",
    "    words = []\n",
    "    for node in tree.findall('.//p/span'):\n",
    "        words.append(node.text)\n",
    "\n",
    "    #print(\"Time Taken to extract the text from the xml file:\",timeit.default_timer() - start_time)\n",
    "\n",
    "    #filter the words from xml file and whisper output\n",
    "\n",
    "    start_timer = timeit.default_timer()\n",
    "\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        if word == None:\n",
    "            continue\n",
    "        elif '[' not in word:\n",
    "            if ':' not in word:\n",
    "                filtered_words.append(word)\n",
    "\n",
    "    #get sets of filtered words and whisper output\n",
    "    set_whisper_output = set(whisper_output)\n",
    "    set_filtered_words = set(filtered_words)\n",
    "    #convert the lists to string\n",
    "    whisper_output_str = ' '.join(whisper_output)\n",
    "    filtered_words_str = ' '.join(filtered_words)\n",
    "    print('$'*20)\n",
    "    print()\n",
    "    print(\"Number of words in the video:\",len(set_whisper_output))\n",
    "    print(\"Number of words in the xml file:\",len(set_filtered_words))\n",
    "    print('$'*20)\n",
    "    print()\n",
    "    #calculate unique words in the video and xml file\n",
    "    print(\"Number of unique words in the video:\",len(set_whisper_output - set_filtered_words))\n",
    "    print(\"Number of unique words in the xml file:\",len(set_filtered_words - set_whisper_output))\n",
    "    print('$'*20)\n",
    "    print()\n",
    "    #print(\"Time Taken to process the string:\",timeit.default_timer() - start_timer)\n",
    "\n",
    "    #calculate levenshitn distance between the two strings\n",
    "    start_timer = timeit.default_timer()\n",
    "    print(filtered_words_str[:20])\n",
    "    print(whisper_output_str[:20])\n",
    "    with open(audio_file_path.split('/')[-1]+str(model_type)+'.txt', \"w\") as text_file:\n",
    "        text_file.write(whisper_output_str.lower())\n",
    "    levenshitn_distance = distance(filtered_words_str.lower(),whisper_output_str.lower())/len(filtered_words_str)\n",
    "    print(\"Levenshtein distance between xml words and whisper output:\", levenshitn_distance)\n",
    "            #distance(filtered_words_str.lower(),whisper_output_str.lower())/len(filtered_words_str))\n",
    "    print('$'*20)\n",
    "    print()\n",
    "    print(\"Time Taken to calculate levenshtein distance:\",timeit.default_timer() - start_timer)\n",
    "\n",
    "    print('#'*50)\n",
    "\n",
    "    return transcription_time, levenshitn_distance, len(set_filtered_words - set_whisper_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call function on all the files, report comparison stats and save graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['21259.1.xml', '21259.2.xml', '43666.1.xml', '43666.2.xml', '5891.1.xml', '5891.5.xml', '9908.1.xml', '9908.2.xml'] ['21259-01-V01-5000000002053816.mp3', '21259-02-V01-5000000002053837.mp3', '43666-01-V01-5000000002836675.mp3', '43666-02-V01-5000000002836696.mp3', '5891-01-V01-1279244.mp3', '5891-05-V01-1277108.mp3', '9908-01-V01-1329158.mp3', '9908-02-V01-1328710.mp3']\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/21259-01-V01-5000000002053816.mp3\n",
      "xml file path: 21259.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 215.85463279800024\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 939\n",
      "Number of words in the xml file: 1134\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 452\n",
      "Number of unique words in the xml file: 647\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "My name is Manuel Be\n",
      "....................\n",
      "Levenshtein distance between xml words and whisper output: 0.3683451700752924\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.5944107979994442\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/21259-02-V01-5000000002053837.mp3\n",
      "xml file path: 21259.2.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 189.1308265079988\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1009\n",
      "Number of words in the xml file: 1157\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 446\n",
      "Number of unique words in the xml file: 594\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Mr. Bekler, we were \n",
      "Mr. Beckler, we're t\n",
      "Levenshtein distance between xml words and whisper output: 0.3133801201779735\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.7831484960006492\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/43666-01-V01-5000000002836675.mp3\n",
      "xml file path: 43666.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 142.35752507399957\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 924\n",
      "Number of words in the xml file: 960\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 346\n",
      "Number of unique words in the xml file: 382\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Today is July 13, 19\n",
      "Today is July 13, 19\n",
      "Levenshtein distance between xml words and whisper output: 0.22227686255224982\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.43793553700015764\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/43666-02-V01-5000000002836696.mp3\n",
      "xml file path: 43666.2.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 152.3549782099999\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 891\n",
      "Number of words in the xml file: 1006\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 313\n",
      "Number of unique words in the xml file: 428\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Tape two, Ella Davis\n",
      "Take two Ella Davis.\n",
      "Levenshtein distance between xml words and whisper output: 0.24648661153201087\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.49881290499979514\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/5891-01-V01-1279244.mp3\n",
      "xml file path: 5891.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 176.21891390599922\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1279\n",
      "Number of words in the xml file: 1390\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 418\n",
      "Number of unique words in the xml file: 529\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "1995. We're with a s\n",
      "a survey We are with\n",
      "Levenshtein distance between xml words and whisper output: 0.20449289725801123\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 1.0127395460003754\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/5891-05-V01-1277108.mp3\n",
      "xml file path: 5891.5.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 177.8022169420001\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1244\n",
      "Number of words in the xml file: 1599\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 458\n",
      "Number of unique words in the xml file: 813\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "So you were telling \n",
      "So you were telling \n",
      "Levenshtein distance between xml words and whisper output: 0.2191915375897242\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 1.1841018499999336\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/9908-01-V01-1329158.mp3\n",
      "xml file path: 9908.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 149.94785291099834\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 977\n",
      "Number of words in the xml file: 1041\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 352\n",
      "Number of unique words in the xml file: 416\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "OK. Today is Februar\n",
      "Today is February th\n",
      "Levenshtein distance between xml words and whisper output: 0.20918696044324184\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.4124208520006505\n",
      "##################################################\n",
      "#### NEW VIDEO TINY####\n",
      "audio file path: audio/9908-02-V01-1328710.mp3\n",
      "xml file path: 9908.2.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 130.63430506700024\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 970\n",
      "Number of words in the xml file: 1005\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 400\n",
      "Number of unique words in the xml file: 435\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "I'm conducting an in\n",
      "I'm conducting an in\n",
      "Levenshtein distance between xml words and whisper output: 0.22126225490196078\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.4427379699991434\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/21259-01-V01-5000000002053816.mp3\n",
      "xml file path: 21259.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 324.3547755519994\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1001\n",
      "Number of words in the xml file: 1134\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 442\n",
      "Number of unique words in the xml file: 575\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "My name is Manuel Be\n",
      "... My name is Manue\n",
      "Levenshtein distance between xml words and whisper output: 0.2836012174934586\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.5918300250013999\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/21259-02-V01-5000000002053837.mp3\n",
      "xml file path: 21259.2.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 316.2987412730017\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1013\n",
      "Number of words in the xml file: 1157\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 405\n",
      "Number of unique words in the xml file: 549\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Mr. Bekler, we were \n",
      "Mr. Bechler, we're t\n",
      "Levenshtein distance between xml words and whisper output: 0.2750791248107885\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.7776293649985746\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/43666-01-V01-5000000002836675.mp3\n",
      "xml file path: 43666.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 207.6687996340006\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 853\n",
      "Number of words in the xml file: 960\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 257\n",
      "Number of unique words in the xml file: 364\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Today is July 13, 19\n",
      "Today is July 13, 19\n",
      "Levenshtein distance between xml words and whisper output: 0.196520776985493\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.42952788500042516\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/43666-02-V01-5000000002836696.mp3\n",
      "xml file path: 43666.2.xml\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to transcribe the audio file: 237.0943705919999\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 857\n",
      "Number of words in the xml file: 1006\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 271\n",
      "Number of unique words in the xml file: 420\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Tape two, Ella Davis\n",
      "Take two Ella Davis.\n",
      "Levenshtein distance between xml words and whisper output: 0.20889480076340292\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.501264064998395\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/5891-01-V01-1279244.mp3\n",
      "xml file path: 5891.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 257.93086259400116\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1232\n",
      "Number of words in the xml file: 1390\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 341\n",
      "Number of unique words in the xml file: 499\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "1995. We're with a s\n",
      "opa tell you 1995 we\n",
      "Levenshtein distance between xml words and whisper output: 0.21271060455896929\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.963438386001144\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/5891-05-V01-1277108.mp3\n",
      "xml file path: 5891.5.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 310.533877418\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1238\n",
      "Number of words in the xml file: 1599\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 432\n",
      "Number of unique words in the xml file: 793\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "So you were telling \n",
      "So you were telling \n",
      "Levenshtein distance between xml words and whisper output: 0.19335096335474122\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 1.1946674040009384\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/9908-01-V01-1329158.mp3\n",
      "xml file path: 9908.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 243.67005302199868\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 981\n",
      "Number of words in the xml file: 1041\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 322\n",
      "Number of unique words in the xml file: 382\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "OK. Today is Februar\n",
      "Today is February 18\n",
      "Levenshtein distance between xml words and whisper output: 0.183739208864837\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.4071252200010349\n",
      "##################################################\n",
      "#### NEW VIDEO BASE####\n",
      "audio file path: audio/9908-02-V01-1328710.mp3\n",
      "xml file path: 9908.2.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 204.6138350429992\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 966\n",
      "Number of words in the xml file: 1005\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 318\n",
      "Number of unique words in the xml file: 357\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "I'm conducting an in\n",
      "I'm conducting an in\n",
      "Levenshtein distance between xml words and whisper output: 0.19031862745098038\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.4443627370001195\n",
      "##################################################\n",
      "#### NEW VIDEO SMALL####\n",
      "audio file path: audio/21259-01-V01-5000000002053816.mp3\n",
      "xml file path: 21259.1.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 430.95873122800003\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1\n",
      "Number of words in the xml file: 1134\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 1\n",
      "Number of unique words in the xml file: 1134\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "My name is Manuel Be\n",
      "....................\n",
      "Levenshtein distance between xml words and whisper output: 0.9808298179099696\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.03787718000057794\n",
      "##################################################\n",
      "#### NEW VIDEO SMALL####\n",
      "audio file path: audio/21259-02-V01-5000000002053837.mp3\n",
      "xml file path: 21259.2.xml\n",
      "##################################################\n",
      "Time Taken to transcribe the audio file: 658.620280354\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of words in the video: 1008\n",
      "Number of words in the xml file: 1157\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Number of unique words in the video: 353\n",
      "Number of unique words in the xml file: 502\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Mr. Bekler, we were \n",
      "Mr. Beckler, we were\n",
      "Levenshtein distance between xml words and whisper output: 0.21966882253107656\n",
      "$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "Time Taken to calculate levenshtein distance: 0.7837486139997054\n",
      "##################################################\n",
      "#### NEW VIDEO SMALL####\n",
      "audio file path: audio/43666-01-V01-5000000002836675.mp3\n",
      "xml file path: 43666.1.xml\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "#    video_files = []\n",
    "#    for file in os.listdir('Data/'):\n",
    "#        if file.endswith('.mp4'):\n",
    "#            video_files.append(file)\n",
    "#    video_files.sort()\n",
    "\n",
    "xml_files = []\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith('.xml'):\n",
    "        xml_files.append(file)\n",
    "xml_files.sort()\n",
    "#print(video_files, xml_files)\n",
    "\n",
    "#convert video mp4 to mp3\n",
    "#for video_file in video_files:\n",
    "#  convert_video_to_audio('Data/'+ video_file)\n",
    "\n",
    "audio_files = []\n",
    "for file in os.listdir('audio/'):\n",
    "    if file.endswith('.mp3'):\n",
    "        audio_files.append(file)\n",
    "audio_files.sort()\n",
    "\n",
    "print(xml_files, audio_files)\n",
    "\n",
    "\n",
    "TIME = []\n",
    "DISTANCE = []\n",
    "WORDS = []\n",
    "#    print(audio_files)\n",
    "tiny_time = []\n",
    "tiny_distance = []\n",
    "tiny_words = []\n",
    "for i in range(len(audio_files)):\n",
    "    print(\"#### NEW VIDEO TINY####\")\n",
    "    time , dist, words = compare(audio_files[i],xml_files[i], \"tiny.en\")\n",
    "    tiny_time.append(time)\n",
    "    tiny_distance.append(dist)\n",
    "    tiny_words.append(words)\n",
    "TIME.append(tiny_time)\n",
    "DISTANCE.append(tiny_distance)\n",
    "WORDS.append(tiny_words)\n",
    "\n",
    "base_time = []\n",
    "base_distance = []\n",
    "base_words = []\n",
    "for i in range(len(audio_files)):\n",
    "    print(\"#### NEW VIDEO BASE####\")\n",
    "    time , dist, words = compare(audio_files[i],xml_files[i], \"base.en\")\n",
    "    base_time.append(time)\n",
    "    base_distance.append(dist)\n",
    "    base_words.append(words)\n",
    "TIME.append(base_time)\n",
    "DISTANCE.append(base_distance)\n",
    "WORDS.append(base_words)\n",
    "\n",
    "small_time = []\n",
    "small_distance = []\n",
    "small_words = []\n",
    "for i in range(len(audio_files)):\n",
    "    print(\"#### NEW VIDEO SMALL####\")\n",
    "    time , dist, words = compare(audio_files[i],xml_files[i], \"small.en\")\n",
    "    small_time.append(time)\n",
    "    small_distance.append(dist)\n",
    "    small_words.append(words)\n",
    "TIME.append(small_time)\n",
    "DISTANCE.append(small_distance)\n",
    "WORDS.append(small_words)\n",
    "\n",
    "#    medium_time = []\n",
    "#    medium_distance = []\n",
    "#    medium_words = []\n",
    "#    print(\"Medium Model\")\n",
    "#    for i in range(len(audio_files)):\n",
    "#        print(\"#### NEW VIDEO MEDIUM ####\")\n",
    "#        time , dist, words = compare(audio_files[i],xml_files[i], \"medium.en\")\n",
    "#        medium_time.append(time)\n",
    "#        medium_distance.append(dist)\n",
    "#        medium_words.append(words)\n",
    "#    TIME.append(medium_time)\n",
    "#    DISTANCE.append(medium_distance)\n",
    "#    WORDS.append(medium_words)\n",
    "\n",
    "#save TIME and DISTANCE in json format\n",
    "with open('time.json', 'w') as f:\n",
    "    json.dump(TIME, f)\n",
    "with open('distance.json', 'w') as f:\n",
    "    json.dump(DISTANCE, f)\n",
    "with open('words.json', 'w') as f:\n",
    "    json.dump(WORDS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(TIME[0], DISTANCE[0], label = 'tiny')\n",
    "plt.scatter(TIME[1], DISTANCE[1], label = 'base')\n",
    "plt.scatter(TIME[2], DISTANCE[2], label = 'small')\n",
    "#     plt.scatter(TIME[3], DISTANCE[3], label = 'medium')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Levenshtein Distance')\n",
    "plt.title('Levenshtein Distance vs Time')\n",
    "plt.legend()\n",
    "plt.savefig('levenshtein_distance_vs_time.png')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(WORDS[0], DISTANCE[0], label = 'tiny')  \n",
    "plt.scatter(WORDS[1], DISTANCE[1], label = 'base')\n",
    "plt.scatter(WORDS[2], DISTANCE[2], label = 'small') \n",
    "#    plt.scatter(WORDS[3], DISTANCE[3], label = 'medium')\n",
    "\n",
    "plt.xlabel('Number of words')\n",
    "plt.ylabel('Levenshtein Distance')\n",
    "plt.title('Levenshtein Distance vs Number of words')\n",
    "plt.legend()\n",
    "plt.savefig('levenshtein_distance_vs_words.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7Woh5ImzIYZMhASR8H9EB",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e42701c7312a0acf303ea5e8d69e18f8e37004062c0c49da56548b53e5cf4e88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
